{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178957ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIGURATION\n",
    "ROLLING_WINDOW = 50\n",
    "NUM_PREDICTIONS = 5\n",
    "TICK_THRESHOLD = 0.0005  # Reduced threshold for more sensitivity\n",
    "FEATURE_COLUMNS = []  # Populated later\n",
    "\n",
    "\n",
    "\n",
    "def rolling_slope(series, window):\n",
    "    \"\"\"Calculate rolling linear regression slope\"\"\"\n",
    "    slopes = np.full(len(series), np.nan)\n",
    "    for i in range(window, len(series)):\n",
    "        y = series.iloc[i-window:i]\n",
    "        x = np.arange(window)\n",
    "        slope, _, _, _, _ = linregress(x, y)\n",
    "        slopes[i] = slope\n",
    "    return slopes\n",
    "\n",
    "def rolling_hurst(series, window):\n",
    "    \"\"\"Calculate rolling Hurst exponent\"\"\"\n",
    "    hurst_vals = np.full(len(series), np.nan)\n",
    "    for i in range(window, len(series)):\n",
    "        window_data = series.iloc[i-window:i]\n",
    "        if window_data.std() == 0:\n",
    "            hurst_vals[i] = 0.5\n",
    "            continue\n",
    "        lags = range(2, window)\n",
    "        tau = [np.std(np.subtract(window_data[lag:], window_data[:-lag])) for lag in lags]\n",
    "        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "        hurst_vals[i] = poly[0]*2.0\n",
    "    return hurst_vals\n",
    "\n",
    "def rogers_satchell_vol(high, low, close, open_, window):\n",
    "    \"\"\"Calculate Rogers-Satchell volatility estimator\"\"\"\n",
    "    rs = np.log(high/open_) * np.log(high/close) + np.log(low/open_) * np.log(low/close)\n",
    "    return rs.rolling(window).std()\n",
    "\n",
    "def rolling_autocorr(series, window):\n",
    "    \"\"\"Calculate rolling autocorrelation\"\"\"\n",
    "    ac = np.full(len(series), np.nan)\n",
    "    for i in range(window, len(series)):\n",
    "        ac[i] = series.iloc[i-window:i].autocorr(lag=1)\n",
    "    return ac\n",
    "\n",
    "def calculate_rsi(prices, window):\n",
    "    \"\"\"Calculate RSI indicator\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=1).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=1).mean()\n",
    "    rs = gain / (loss + 1e-8)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def process_tick_data_to_candles():\n",
    "    \"\"\"Convert tick data to 15-minute candles with all features\"\"\"\n",
    "\n",
    "    dfs_temp = []\n",
    "    FILE_PATTERN=r\"C:\\Users\\aditya-tanwar\\OneDrive - MMC\\Documents\\my_work\\study_work\\data\\\\\"\n",
    "\n",
    "    chunk_files = os.listdir(FILE_PATTERN)#['chunk_0001.parquet', 'chunk_0002.parquet', 'chunk_0003.parquet', 'chunk_0004.parquet']\n",
    "    print(1)\n",
    "    \n",
    "    for file in chunk_files:\n",
    "        try:\n",
    "            df_temp = pd.read_parquet(FILE_PATTERN+file)\n",
    "            # Filter for Trade data and clean\n",
    "            df_temp = df_temp[df_temp['Type'] == 'Trade'].dropna(subset=['Price', 'Volume'])\n",
    "            df_temp=df_temp[['Date-Time', 'GMT Offset', 'Price', 'Volume', 'Bid Price', 'Ask Price']]\n",
    "            df_temp['GMT Offset'] += 7\n",
    "            df_temp['Date-Time'] = pd.to_datetime(df_temp['Date-Time']) + pd.to_timedelta(df_temp['GMT Offset'], unit='h')\n",
    "            df_temp['candle_time'] = df_temp['Date-Time'].dt.floor('15min')\n",
    "            dfs_temp.append(df_temp[['Date-Time', 'Price', 'Volume', 'candle_time']])\n",
    "            print(f\"Loaded {len(df_temp)} trades from {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    if not dfs_temp:\n",
    "        raise ValueError(\"No data loaded successfully\")\n",
    "    \n",
    "    # Combine all data\n",
    "    df = pd.concat(dfs_temp).sort_values('Date-Time')\n",
    "    df['day'] = df['Date-Time'].dt.date\n",
    "\n",
    "\n",
    "    # Tick logic: count a tick every time price changes\n",
    "    df['price_change'] = df['Price'].diff().fillna(0) != 0\n",
    "    df['tick_id'] = df.groupby('day')['price_change'].cumsum()\n",
    "    print(2)\n",
    "    # Aggregate to 15-min candles\n",
    "    candles = df.groupby(['day', 'candle_time']).agg({\n",
    "        'Price': ['first', 'max', 'min', 'last'],\n",
    "        'Volume': 'sum',\n",
    "        'tick_id': 'nunique'\n",
    "    })\n",
    "    candles.columns = ['open', 'high', 'low', 'close', 'volume', 'num_ticks']\n",
    "    candles = candles.reset_index()\n",
    "\n",
    "    # Volume bucket features\n",
    "    bucket_edges = [100, 200, 500, 1000, 2500, 5000,7500,10000,15000,50000]\n",
    "    bucket_names = [f'vol_{bucket_edges[i]}' for i in range(len(bucket_edges))]\n",
    "    tick_names = [f'tick_{bucket_edges[i]}' for i in range(len(bucket_edges))]\n",
    "\n",
    "    for i in range(len(bucket_edges)):\n",
    "        candles[bucket_names[i]] = candles['volume']/bucket_edges[i]\n",
    "        candles[tick_names[i]] = candles['num_ticks']/bucket_edges[i]\n",
    "        \n",
    "    print(3)\n",
    "\n",
    "    # Add small and large volume buckets for order flow\n",
    "    candles['vol_1_5'] = df.groupby(['day', 'candle_time']).apply(\n",
    "        lambda g: ((g['Volume'] >= 1) & (g['Volume'] <= 5)).sum()\n",
    "    ).values\n",
    "    candles['vol_101_plus'] = df.groupby(['day', 'candle_time']).apply(\n",
    "        lambda g: (g['Volume'] > 100).sum()\n",
    "    ).values\n",
    "\n",
    "    # VWAP for each 15-min candle\n",
    "    candles['vwap'] = df.groupby(['day', 'candle_time']).apply(\n",
    "        lambda g: (g['Price'] * g['Volume']).sum() / g['Volume'].sum() if g['Volume'].sum() > 0 else np.nan\n",
    "    ).values\n",
    "    print(4)\n",
    "    # 1-min VWAP for rolling average\n",
    "    one_min = df.copy()\n",
    "    one_min['one_min_time'] = one_min['Date-Time'].dt.floor('1min')\n",
    "    vwap_1m = one_min.groupby(['day', 'one_min_time']).apply(\n",
    "        lambda g: (g['Price'] * g['Volume']).sum() / g['Volume'].sum() if g['Volume'].sum() > 0 else np.nan\n",
    "    )\n",
    "    vwap_1m = vwap_1m.rename('vwap_1m').reset_index()\n",
    "    print(5)\n",
    "    candles['vwap_1m_avg_15'] = np.nan\n",
    "    for idx, row in candles.iterrows():\n",
    "        day = row['day']\n",
    "        candle_time = row['candle_time']\n",
    "        vwap_hist = vwap_1m[(vwap_1m['day'] == day) & (vwap_1m['one_min_time'] <= candle_time)]['vwap_1m'].tail(15)\n",
    "        candles.at[idx, 'vwap_1m_avg_15'] = vwap_hist.mean() if not vwap_hist.empty else np.nan\n",
    "\n",
    "    return candles\n",
    "\n",
    "def add_all_features(candles):\n",
    "    \"\"\"Add all features to candle DataFrame\"\"\"\n",
    "\n",
    "    short_window = 5#max(3, min(5, total_candles // 20))\n",
    "    med_window = 14#max(5, min(10, total_candles // 15))\n",
    "    long_window = 100#max(10, min(20, total_candles // 10))\n",
    "\n",
    "    # Basic moving averages\n",
    "    candles['sma_short'] = candles['close'].rolling(short_window, min_periods=1).mean()\n",
    "    candles['sma_med'] = candles['close'].rolling(med_window, min_periods=1).mean()\n",
    "\n",
    "    candles['linear_slope_'+str(short_window)] = rolling_slope(candles['close'], short_window)\n",
    "    candles['linear_slope_'+str(med_window)] = rolling_slope(candles['close'], med_window)\n",
    "    candles['hurst_'+str(med_window)] = rolling_hurst(candles['close'], med_window)\n",
    "\n",
    "    candles['vol_rogers_satchell_'+str(short_window)] = rogers_satchell_vol(\n",
    "        candles['high'], candles['low'], candles['close'], candles['open'], short_window\n",
    "    )\n",
    "\n",
    "    # Quantile bins\n",
    "    q0 = candles['close'].rolling(long_window, min_periods=1).quantile(0.0)\n",
    "    q25 = candles['close'].rolling(long_window, min_periods=1).quantile(0.25)\n",
    "    q75 = candles['close'].rolling(long_window, min_periods=1).quantile(0.75)\n",
    "    q108 = candles['close'].rolling(long_window, min_periods=1).quantile(1.0)\n",
    "    candles['bin_0_25'] = ((candles['close'] >= q0) & (candles['close'] < q25)).astype(int)\n",
    "    candles['bin_25_75'] = ((candles['close'] >= q25) & (candles['close'] < q75)).astype(int)\n",
    "    candles['bin_75_108'] = ((candles['close'] >= q75) & (candles['close'] <= q108)).astype(int)\n",
    "\n",
    "    #candles['auto_corr_6'] = rolling_autocorr(candles['close'], 6)\n",
    "\n",
    "    # Relative transformations\n",
    "    candles['pct_linear_slope'] = (candles['linear_slope_'+str(short_window)] - candles['linear_slope_'+str(med_window)]) / candles['vol_rogers_satchell_'+str(short_window)]\n",
    "\n",
    "    # VWAP features\n",
    "    candles['vwap_ratio_short'] = candles['close'] / ((candles['vwap']+candles['vwap_1m_avg_15'])/2)\n",
    "    candles['vwap_distance_short'] = (candles['close'] - ((candles['vwap']+candles['vwap_1m_avg_15'])/2)) / ((candles['vwap']+candles['vwap_1m_avg_15'])/2)\n",
    "\n",
    "    # Order flow features\n",
    "    candles['imbalance'] = (candles['vol_1_5'] - candles['vol_101_plus']) / (candles['vol_1_5'] + candles['vol_101_plus'] + 1e-8)\n",
    "    candles['small_vol_ratio'] = candles['vol_1_5'] / (candles['volume'] + 1e-8)\n",
    "    candles['large_vol_ratio'] = candles['vol_101_plus'] / (candles['volume'] + 1e-8)\n",
    "\n",
    "    # RSI momentum\n",
    "    candles['rsi_short'] = calculate_rsi(candles['close'],short_window)\n",
    "    candles['rsi_med'] = calculate_rsi(candles['close'], med_window)\n",
    "\n",
    "    # Trend features\n",
    "    candles['sma_cross'] = candles['sma_short'] - candles['sma_med']\n",
    "\n",
    "\n",
    "    # VWAP features\n",
    "    candles['vwap_short'] = candles['vwap'].rolling(short_window).mean()\n",
    "    candles['vwap_med'] = candles['vwap'].rolling(med_window).mean()\n",
    "    candles['vwap_long_short'] = candles['vwap_1m_avg_15'].rolling(short_window).mean()\n",
    " \n",
    "    \n",
    "    # Volume features\n",
    "    candles['volume_sma'] = candles['volume'].rolling(20).mean()\n",
    "    candles['volume_ratio'] = candles['volume'] / candles['volume_sma']\n",
    "    candles['volume_momentum'] = candles['volume'].pct_change(5)\n",
    "    \n",
    "    # Tick intensity features\n",
    "    candles['tick_intensity'] = candles['num_ticks'] / candles['num_ticks'].rolling(20).mean()\n",
    "    candles['tick_momentum'] = candles['num_ticks'].pct_change(3)\n",
    "    \n",
    "    # Price range features\n",
    "    candles['high_low_ratio'] = (candles['high'] - candles['low']) / candles['close']\n",
    "    candles['close_position'] = (candles['close'] - candles['low']) / (candles['high'] - candles['low'])\n",
    "    \n",
    "    # Advanced features\n",
    "    candles['price_acceleration'] = candles['close'].pct_change().diff()\n",
    "    candles['volume_price_trend'] = candles['volume'] * candles['close'].pct_change()\n",
    "    \n",
    "    # Rolling statistics\n",
    "    \n",
    "    # Enhanced tick-volume velocity\n",
    "    candles['rolling_ticks'] = candles['num_ticks'].rolling(window=5, min_periods=1).sum()\n",
    "    candles['rolling_volume'] = candles['volume'].rolling(window=5, min_periods=1).sum()\n",
    "    candles['price_change_pct'] = candles['close'].pct_change(periods=5)\n",
    "    candles['tick_volume_velocity'] = (candles['price_change_pct'] * candles['rolling_ticks']) / (candles['rolling_volume'] + 1e-8)\n",
    "    \n",
    "    # Define feature columns (excluding basic OHLCV)\n",
    "    global FEATURE_COLUMNS\n",
    "    FEATURE_COLUMNS = [col for col in candles.columns if col not in ['candle_time', 'open', 'high', 'low', 'close', 'volume', 'num_ticks']]\n",
    "    \n",
    "    # Fill missing values\n",
    "    for col in FEATURE_COLUMNS:\n",
    "        candles[col] = candles[col].fillna(method='ffill').fillna(0)\n",
    "        # Replace infinite values\n",
    "        candles[col] = candles[col].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(f\"Created {len(FEATURE_COLUMNS)} features for classification\")\n",
    "    candles.to_csv('ESc1_featured_candles.csv')\n",
    "\n",
    "\n",
    "    return candles\n",
    "\n",
    "\n",
    "\n",
    "# STEP 3: Enhanced classification with multiple models\n",
    "def run_classification_predictions(candles, window=ROLLING_WINDOW, num_preds=NUM_PREDICTIONS):\n",
    "    results = []\n",
    "    \n",
    "    # Create target variable with multiple thresholds\n",
    "    y_ret = candles['close'].pct_change().shift(-1)\n",
    "    candles['y_class'] = np.select(\n",
    "        [y_ret < -TICK_THRESHOLD, y_ret > TICK_THRESHOLD], \n",
    "        [-1, 1], \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    print(f\"Target distribution: {candles['y_class'].value_counts().sort_index()}\")\n",
    "    \n",
    "    # Track model performance\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for i in range(window, window + num_preds):\n",
    "        print(i)\n",
    "        train = candles.iloc[i-window:i].copy()\n",
    "        test = candles.iloc[i:i+1]\n",
    "        \n",
    "        # Prepare training data\n",
    "        X_train = train[FEATURE_COLUMNS].iloc[:-1]  # Remove last row to align with shifted target\n",
    "        y_train = train['y_class'].shift(-1).iloc[:-1].dropna()\n",
    "        \n",
    "        # Ensure alignment\n",
    "        min_len = min(len(X_train), len(y_train))\n",
    "        X_train = X_train.iloc[:min_len]\n",
    "        y_train = y_train.iloc[:min_len]\n",
    "        print(len(X_train), len(y_train))\n",
    "        \n",
    "        if len(X_train) < 30 or len(y_train.unique()) < 2:\n",
    "    \n",
    "            continue\n",
    "        \n",
    "        #Train multiple models and ensemble\n",
    "        models = {\n",
    "            'gb': GradientBoostingClassifier(\n",
    "                n_estimators=100, \n",
    "                max_depth=6, \n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8,\n",
    "                random_state=42\n",
    "            ),\n",
    "            'rf': RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=8,\n",
    "                min_samples_split=10,\n",
    "                random_state=42\n",
    "            )\n",
    "        }\n",
    "        # models = {\n",
    "        #     'gb': GradientBoostingClassifier(\n",
    "        #         n_estimators=100, \n",
    "        #         max_depth=6, \n",
    "        #         learning_rate=0.1,\n",
    "        #         subsample=0.8,\n",
    "        #         random_state=42\n",
    "        #     )\n",
    "        # }\n",
    "\n",
    "\n",
    "        # models = {\n",
    "        #     'gb': GradientBoostingClassifier(\n",
    "        #         n_estimators=100, \n",
    "        #         max_depth=6, \n",
    "        #         learning_rate=0.1,\n",
    "        #         subsample=0.8,\n",
    "        #         random_state=42\n",
    "        #     )\n",
    "        # }\n",
    "        \n",
    "        # Train models\n",
    "        trained_models = {}\n",
    "        for name, model in models.items():\n",
    "            try:\n",
    "                print(1)\n",
    "                model.fit(X_train, y_train)\n",
    "                trained_models[name] = model\n",
    "            except Exception as e:\n",
    "                print(f\"Error training {name}: {e}\")\n",
    "        \n",
    "        if not trained_models:\n",
    "            print(1)\n",
    "            continue\n",
    "        \n",
    "        # Make predictions\n",
    "        X_test = test[FEATURE_COLUMNS]\n",
    "        predictions = {}\n",
    "        probabilities = {}\n",
    "        \n",
    "        for name, model in trained_models.items():\n",
    "            pred = model.predict(X_test)[0]\n",
    "            proba = model.predict_proba(X_test)[0]\n",
    "            predictions[name] = pred\n",
    "            probabilities[name] = proba\n",
    "        \n",
    "        # Ensemble prediction (majority vote)\n",
    "        pred_values = list(predictions.values())\n",
    "        ensemble_pred = max(set(pred_values), key=pred_values.count)\n",
    "        \n",
    "        # Average probabilities\n",
    "        avg_proba = np.mean([prob for prob in probabilities.values()], axis=0)\n",
    "        \n",
    "        \n",
    "        actual = int(test['y_class'].values[0])\n",
    "        \n",
    "        # Track accuracy\n",
    "        if ensemble_pred == actual:\n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "        \n",
    "        results.append({\n",
    "            'timestamp': test['candle_time'].values[0],\n",
    "            'pred_direction': int(ensemble_pred),\n",
    "            'actual_direction': actual,\n",
    "            'prob_down': avg_proba[0] if len(avg_proba) > 0 else np.nan,\n",
    "            'prob_flat': avg_proba[1] if len(avg_proba) > 1 else np.nan,\n",
    "            'prob_up': avg_proba[2] if len(avg_proba) > 2 else np.nan,\n",
    "            'actual_close': test['close'].values[0],\n",
    "            'actual_volume': test['volume'].values[0],\n",
    "            'gb_pred': predictions.get('gb', np.nan),\n",
    "            'rf_pred': predictions.get('rf', np.nan)\n",
    "        })\n",
    "        \n",
    "        if total_predictions % 50 == 0:\n",
    "            current_acc = (correct_predictions / total_predictions) * 100\n",
    "            print(f\"Progress: {total_predictions}/{num_preds}, Current Accuracy: {current_acc:.2f}%\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c29060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading data from uploaded files...\n",
      "1\n",
      "Loaded 1999098 trades from chunk_0001.parquet\n",
      "Loaded 1999197 trades from chunk_0002.parquet\n",
      "Loaded 1998776 trades from chunk_0003.parquet\n",
      "Loaded 1998550 trades from chunk_0004.parquet\n",
      "Loaded 1997862 trades from chunk_0005.parquet\n",
      "Loaded 1998262 trades from chunk_0006.parquet\n",
      "Loaded 1997709 trades from chunk_0007.parquet\n",
      "Loaded 1997670 trades from chunk_0008.parquet\n",
      "Loaded 1996536 trades from chunk_0009.parquet\n",
      "Loaded 1996356 trades from chunk_0010.parquet\n",
      "Loaded 1994163 trades from chunk_0011.parquet\n",
      "Loaded 1993367 trades from chunk_0012.parquet\n",
      "Loaded 1987296 trades from chunk_0013.parquet\n",
      "Loaded 1977451 trades from chunk_0014.parquet\n",
      "Loaded 1807645 trades from chunk_0015.parquet\n",
      "Loaded 1999315 trades from chunk_0016.parquet\n",
      "Loaded 1998650 trades from chunk_0017.parquet\n",
      "Loaded 1997593 trades from chunk_0018.parquet\n",
      "Loaded 1996897 trades from chunk_0019.parquet\n",
      "Loaded 1996938 trades from chunk_0020.parquet\n",
      "Loaded 1997550 trades from chunk_0021.parquet\n",
      "Loaded 1998827 trades from chunk_0022.parquet\n",
      "Loaded 1998563 trades from chunk_0023.parquet\n",
      "Loaded 1998630 trades from chunk_0024.parquet\n",
      "Loaded 1998060 trades from chunk_0025.parquet\n",
      "Loaded 1998016 trades from chunk_0026.parquet\n",
      "Loaded 1994249 trades from chunk_0027.parquet\n",
      "Loaded 1995275 trades from chunk_0028.parquet\n",
      "Loaded 1994791 trades from chunk_0029.parquet\n",
      "Loaded 1993373 trades from chunk_0030.parquet\n",
      "Loaded 1969757 trades from chunk_0031.parquet\n",
      "Loaded 1085479 trades from chunk_0032.parquet\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "🧠 Adding enhanced classification features... 0:10:07.124521\n",
      "Created 59 features for classification\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"📥 Loading data from uploaded files...\")\n",
    "current_time = datetime.now()\n",
    "\n",
    "candles_pre = process_tick_data_to_candles()\n",
    "next_time = datetime.now()\n",
    "\n",
    "print(\"🧠 Adding enhanced classification features...\",next_time-current_time)\n",
    "candles = add_all_features(candles_pre)\n",
    "next_time1 = datetime.now()\n",
    "\n",
    "\n",
    "# print(\"🚀 Running classification predictions...\",next_time1-next_time)\n",
    "# results_df = run_classification_predictions(candles)\n",
    "\n",
    "# if len(results_df) > 0:\n",
    "#     # Calculate accuracy\n",
    "#     acc = (results_df['pred_direction'] == results_df['actual_direction']).mean() * 100\n",
    "#     print(f\"\\n🎯 Final Classification Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "#     # Detailed performance analysis\n",
    "#     print(\"\\n📊 Performance Analysis:\")\n",
    "#     print(\"Confusion Matrix:\")\n",
    "#     print(confusion_matrix(results_df['actual_direction'], results_df['pred_direction']))\n",
    "    \n",
    "#     print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(results_df['actual_direction'], results_df['pred_direction']))\n",
    "    \n",
    "#     # Direction-wise accuracy\n",
    "#     for direction in [-1, 0, 1]:\n",
    "#         subset = results_df[results_df['actual_direction'] == direction]\n",
    "#         if len(subset) > 0:\n",
    "#             dir_acc = (subset['pred_direction'] == direction).mean() * 100\n",
    "#             direction_name = {-1: 'DOWN', 0: 'FLAT', 1: 'UP'}[direction]\n",
    "#             print(f\"{direction_name} accuracy: {dir_acc:.2f}% ({len(subset)} samples)\")\n",
    "    \n",
    "#     print(f\"\\n✅ Results ready! Total predictions: {len(results_df)}\")\n",
    "# else:\n",
    "#     print(\"❌ No predictions generated. Check data and parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a3d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed76a992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>candle_time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>num_ticks</th>\n",
       "      <th>vol_100_199</th>\n",
       "      <th>vol_200_499</th>\n",
       "      <th>...</th>\n",
       "      <th>price_acceleration</th>\n",
       "      <th>volume_price_trend</th>\n",
       "      <th>price_zscore</th>\n",
       "      <th>volume_zscore</th>\n",
       "      <th>trend_strength</th>\n",
       "      <th>rolling_ticks</th>\n",
       "      <th>rolling_volume</th>\n",
       "      <th>price_change_pct</th>\n",
       "      <th>tick_volume_velocity</th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>2025-01-07 18:30:00+00:00</td>\n",
       "      <td>5979.75</td>\n",
       "      <td>5980.25</td>\n",
       "      <td>5969.50</td>\n",
       "      <td>5970.50</td>\n",
       "      <td>23040.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>23040.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>2025-01-07 18:45:00+00:00</td>\n",
       "      <td>5970.50</td>\n",
       "      <td>5976.75</td>\n",
       "      <td>5962.75</td>\n",
       "      <td>5975.75</td>\n",
       "      <td>37796.0</td>\n",
       "      <td>2188</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.234905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>60836.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>2025-01-07 19:00:00+00:00</td>\n",
       "      <td>5976.00</td>\n",
       "      <td>5986.50</td>\n",
       "      <td>5975.00</td>\n",
       "      <td>5985.00</td>\n",
       "      <td>31261.0</td>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>48.389616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5613.0</td>\n",
       "      <td>92097.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>2025-01-07 19:15:00+00:00</td>\n",
       "      <td>5984.75</td>\n",
       "      <td>5991.00</td>\n",
       "      <td>5981.75</td>\n",
       "      <td>5989.50</td>\n",
       "      <td>26799.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>20.149624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6899.0</td>\n",
       "      <td>118896.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>2025-01-07 19:30:00+00:00</td>\n",
       "      <td>5989.50</td>\n",
       "      <td>5989.50</td>\n",
       "      <td>5974.00</td>\n",
       "      <td>5976.25</td>\n",
       "      <td>31440.0</td>\n",
       "      <td>1832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002964</td>\n",
       "      <td>-69.551716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8731.0</td>\n",
       "      <td>150336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24 20:00:00+00:00</td>\n",
       "      <td>6128.25</td>\n",
       "      <td>6132.50</td>\n",
       "      <td>6123.25</td>\n",
       "      <td>6125.75</td>\n",
       "      <td>43294.0</td>\n",
       "      <td>1583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>-17.661649</td>\n",
       "      <td>-2.321756</td>\n",
       "      <td>0.644559</td>\n",
       "      <td>0.964239</td>\n",
       "      <td>6821.0</td>\n",
       "      <td>183086.0</td>\n",
       "      <td>-0.002483</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24 20:15:00+00:00</td>\n",
       "      <td>6125.50</td>\n",
       "      <td>6132.25</td>\n",
       "      <td>6124.25</td>\n",
       "      <td>6128.00</td>\n",
       "      <td>34505.0</td>\n",
       "      <td>1302</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>12.673754</td>\n",
       "      <td>-1.772163</td>\n",
       "      <td>-0.143055</td>\n",
       "      <td>0.969755</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>177130.0</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24 20:30:00+00:00</td>\n",
       "      <td>6128.25</td>\n",
       "      <td>6130.25</td>\n",
       "      <td>6127.00</td>\n",
       "      <td>6128.50</td>\n",
       "      <td>24137.0</td>\n",
       "      <td>840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>1.969403</td>\n",
       "      <td>-1.532497</td>\n",
       "      <td>-1.005174</td>\n",
       "      <td>0.949862</td>\n",
       "      <td>6459.0</td>\n",
       "      <td>173809.0</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24 20:45:00+00:00</td>\n",
       "      <td>6128.50</td>\n",
       "      <td>6133.25</td>\n",
       "      <td>6127.50</td>\n",
       "      <td>6127.75</td>\n",
       "      <td>28751.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-3.518520</td>\n",
       "      <td>-1.456650</td>\n",
       "      <td>-0.472701</td>\n",
       "      <td>0.913224</td>\n",
       "      <td>6535.0</td>\n",
       "      <td>176416.0</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2025-01-24 21:00:00+00:00</td>\n",
       "      <td>6127.75</td>\n",
       "      <td>6127.75</td>\n",
       "      <td>6127.50</td>\n",
       "      <td>6127.75</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.302571</td>\n",
       "      <td>-2.869656</td>\n",
       "      <td>0.865237</td>\n",
       "      <td>4766.0</td>\n",
       "      <td>132396.0</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1161 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             day               candle_time     open     high      low  \\\n",
       "0     2025-01-07 2025-01-07 18:30:00+00:00  5979.75  5980.25  5969.50   \n",
       "1     2025-01-07 2025-01-07 18:45:00+00:00  5970.50  5976.75  5962.75   \n",
       "2     2025-01-07 2025-01-07 19:00:00+00:00  5976.00  5986.50  5975.00   \n",
       "3     2025-01-07 2025-01-07 19:15:00+00:00  5984.75  5991.00  5981.75   \n",
       "4     2025-01-07 2025-01-07 19:30:00+00:00  5989.50  5989.50  5974.00   \n",
       "...          ...                       ...      ...      ...      ...   \n",
       "1156  2025-01-24 2025-01-24 20:00:00+00:00  6128.25  6132.50  6123.25   \n",
       "1157  2025-01-24 2025-01-24 20:15:00+00:00  6125.50  6132.25  6124.25   \n",
       "1158  2025-01-24 2025-01-24 20:30:00+00:00  6128.25  6130.25  6127.00   \n",
       "1159  2025-01-24 2025-01-24 20:45:00+00:00  6128.50  6133.25  6127.50   \n",
       "1160  2025-01-24 2025-01-24 21:00:00+00:00  6127.75  6127.75  6127.50   \n",
       "\n",
       "        close   volume  num_ticks  vol_100_199  vol_200_499  ...  \\\n",
       "0     5970.50  23040.0       1292            1            0  ...   \n",
       "1     5975.75  37796.0       2188            4            0  ...   \n",
       "2     5985.00  31261.0       2133            0            0  ...   \n",
       "3     5989.50  26799.0       1286            0            0  ...   \n",
       "4     5976.25  31440.0       1832            1            0  ...   \n",
       "...       ...      ...        ...          ...          ...  ...   \n",
       "1156  6125.75  43294.0       1583            1            0  ...   \n",
       "1157  6128.00  34505.0       1302            2            0  ...   \n",
       "1158  6128.50  24137.0        840            0            0  ...   \n",
       "1159  6127.75  28751.0       1030            5            1  ...   \n",
       "1160  6127.75   1709.0         11            0            0  ...   \n",
       "\n",
       "      price_acceleration  volume_price_trend  price_zscore  volume_zscore  \\\n",
       "0               0.000000            0.000000      0.000000       0.000000   \n",
       "1               0.000000           33.234905      0.000000       0.000000   \n",
       "2               0.000669           48.389616      0.000000       0.000000   \n",
       "3              -0.000796           20.149624      0.000000       0.000000   \n",
       "4              -0.002964          -69.551716      0.000000       0.000000   \n",
       "...                  ...                 ...           ...            ...   \n",
       "1156            0.000774          -17.661649     -2.321756       0.644559   \n",
       "1157            0.000775           12.673754     -1.772163      -0.143055   \n",
       "1158           -0.000286            1.969403     -1.532497      -1.005174   \n",
       "1159           -0.000204           -3.518520     -1.456650      -0.472701   \n",
       "1160            0.000122            0.000000     -1.302571      -2.869656   \n",
       "\n",
       "      trend_strength  rolling_ticks  rolling_volume  price_change_pct  \\\n",
       "0           0.000000         1292.0         23040.0          0.000000   \n",
       "1           0.000000         3480.0         60836.0          0.000000   \n",
       "2           0.000000         5613.0         92097.0          0.000000   \n",
       "3           0.000000         6899.0        118896.0          0.000000   \n",
       "4           0.000000         8731.0        150336.0          0.000000   \n",
       "...              ...            ...             ...               ...   \n",
       "1156        0.964239         6821.0        183086.0         -0.002483   \n",
       "1157        0.969755         6592.0        177130.0         -0.001832   \n",
       "1158        0.949862         6459.0        173809.0         -0.001629   \n",
       "1159        0.913224         6535.0        176416.0         -0.001263   \n",
       "1160        0.865237         4766.0        132396.0         -0.000082   \n",
       "\n",
       "      tick_volume_velocity  y_class  \n",
       "0                 0.000000        1  \n",
       "1                 0.000000        1  \n",
       "2                 0.000000        1  \n",
       "3                 0.000000       -1  \n",
       "4                 0.000000        0  \n",
       "...                    ...      ...  \n",
       "1156             -0.000093        0  \n",
       "1157             -0.000068        0  \n",
       "1158             -0.000061        0  \n",
       "1159             -0.000047        0  \n",
       "1160             -0.000003        0  \n",
       "\n",
       "[1161 rows x 70 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df788e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
