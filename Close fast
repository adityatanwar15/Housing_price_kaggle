# Let's execute the provided code and calculate the MAE for the given configuration (train window = 500)

import pandas as pd
import numpy as np
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
import warnings

warnings.filterwarnings("ignore")

# Load Data
file_path = '/mnt/data/ESc1_2025.csv'
df = pd.read_csv(file_path)
df.columns = df.columns.str.strip().str.lower()
df['date-time'] = pd.to_datetime(df['date-time'])
df = df.sort_values('date-time').reset_index(drop=True)

# Feature Engineering
df['close_lag1'] = df['close'].shift(1)
df['vwap_lag1'] = df['vwap'].shift(1)
df['momentum_5'] = df['close'].pct_change(5)
df['volatility_10'] = df['close'].rolling(10).std()
df['target_close_diff_alt'] = df['close'].shift(-1) - df['close']

df['hour'] = df['date-time'].dt.hour
df['dayofweek'] = df['date-time'].dt.dayofweek
df['rel_vol_10'] = df['volume'] / (df['volume'].rolling(10).mean() + 1e-9)
df['bid_momentum'] = df['bid size'] / (df['bid size'].rolling(10).mean() + 1e-9)
df['ask_momentum'] = df['ask size'] / (df['ask size'].rolling(10).mean() + 1e-9)
df['bidask_volume_ratio'] = (df['bid size'] - df['ask size']) / (df['volume'] + 1e-9)
df['vwap_diff'] = df['vwap'] - df['close']
df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
df['dow_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
df['dow_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)

df = df.dropna().reset_index(drop=True)

# Feature Selection
features = [
    'rel_vol_10', 'bid_momentum', 'ask_momentum', 'bidask_volume_ratio', 'vwap_diff',
    'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos',
    'volume', 'vwap', 'close', 'high', 'low',
    'close_lag1', 'vwap_lag1', 'momentum_5', 'volatility_10'
]

X = df[features].to_numpy()
y = df['target_close_diff_alt'].values.reshape(-1, 1)
closes = df['close'].values
timestamps = df['date-time']
hours = df['hour'].values

# Scaling
X_scaler = StandardScaler()
y_scaler = StandardScaler()
X_scaled = X_scaler.fit_transform(X)
y_scaled = y_scaler.fit_transform(y).flatten()

# Training Setup
train_window = 500
retrain_interval = 100
predictions, actuals, times = [], [], []

model = SGDRegressor(
    loss='huber',
    penalty='l2',
    learning_rate='adaptive',
    eta0=0.01,
    alpha=0.0001,
    max_iter=1,
    random_state=42
)
model.fit(X_scaled[:train_window], y_scaled[:train_window])

for i in range(train_window, len(X_scaled) - 1):
    if hours[i] < 10:
        continue

    if (i - train_window) % retrain_interval == 0:
        start = i - train_window
        model = SGDRegressor(
            loss='huber',
            penalty='l2',
            learning_rate='adaptive',
            eta0=0.01,
            alpha=0.0001,
            max_iter=1,
            random_state=42
        )
        model.fit(X_scaled[start:i], y_scaled[start:i])

    x_i = X_scaled[i].reshape(1, -1)
    pred_scaled = model.predict(x_i)[0]
    pred_delta = y_scaler.inverse_transform([[pred_scaled]])[0][0]
    pred_close = closes[i] + pred_delta
    actual_close = closes[i + 1]

    predictions.append(pred_close)
    actuals.append(actual_close)
    times.append(timestamps[i])

# Final Results
result_df = pd.DataFrame({
    'time': pd.to_datetime(times),
    'pred_close': predictions,
    'actual_close': actuals
})
mae_final = mean_absolute_error(result_df['actual_close'], result_df['pred_close'])
mae_final

    
